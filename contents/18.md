### Ubuntu系统安装

1 ） **概述**

- 网上教程一大堆，这里需要特别说明一些问题
- 目前对tensorflow和cuda支持最好的是ubuntu18.04,16.04这种LTS版本的，非LTS的一版不推荐，马上要到2020年的4月份了，可能会出现20.04这种LTS的版本
- Windows可以搭建深度学习GPU环境,但是问题实在很多，不推荐
- 自己用的话选择Ubuntu桌面版，服务器的选择server版，但是这两者是可以切换的
- ubuntu 自带的开源驱动一般都会有问题，1080ti的显卡不支持，可以用服务器版本装好后，再考虑装上桌面
- ubuntu从17.04之后，很多东西都可以装在$HOME/.local下面，省去了很多麻烦
- 如果因驱动问题造成安装时的花屏，可以选择其他带有install ubuntu safe graphics模式的desktop版本(不推荐)或server版本
- 因为驱动问题，大部分人可能会选择server版本, 如果选择不是LTS版本的desktop，那么可能会导致后续的cuda版本与系统不兼容

2 ） **参考**

https://www.cnblogs.com/masbay/p/10745170.html
https://blog.csdn.net/qq_38962621/article/details/87390603
https://blog.csdn.net/a845717607/article/details/98449419
https://blog.csdn.net/qq_22157427/article/details/103298416
https://forum.ubuntu.org.cn/viewtopic.php?t=395050

### 升级

1 ） **配置国内源**

- 装完之后，推荐先升级⼀下系统。试了⼀下，默认的源速度不怎么好，换⼀个国内的源
- 国内的话，有ali，163，tuna，中科⼤
- 参考各个国内源说明⽂档去修改sources.list即可

ali的ubuntu18.04 sources.list设置

```
deb https://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe
multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe
multiverse
deb https://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe
multiverse
```

- 注意：这些最好根据系统版本来进行具体设置，具体可网上搜索
- 或参考这篇文章：https://blog.csdn.net/wy_bk/article/details/89473921
- 也就是说每个版本的Ubuntu的代号和源可能不一样，最好使用匹配版本的

2 ） **执行更新**

- $ `sudo apt-get update`
- $ `sudo apt-get upgrade`

3 ) **重启(很有必要)**

- $ `sudo reboot`

### 软件安装

1 ) **安装 rsync screen aptitude**

- 因为系统⾥⾯现在还啥也没有，安装完之后对系统做⼀个易⽤性的设置
    * $`sudo apt-get install rsync screen aptitude`

2 ) **pip安装**

- 因为我们这⾥是⽤pip安装的各个框架，所以pip要先安装⼀下
- $`sudo aptitude install python3-pip`
- 备注：ubuntu18.04⾥⾯⾃带的已经是python3.6了，如果操作系统使⽤的是ubuntu16.04，其⾃带的python是python3.5，则需要考虑使⽤conda等⼯具安装python3.6之后再进⾏后续的各个框架安装了

3 ） **安装nvidia驱动**

- 想⽤nvidia的显卡，不装nvidia的驱动怎么⾏，其实ubuntu官⽅的仓库⾥⾯是⾃⼰带nvidia的闭源驱动的，不过我们这⾥使⽤的是cuda库⾥⾯⾃带的nvidia驱动
- 查询电脑最适合的显卡驱动版本 $ `ubuntu-drivers devices`
- 使⽤命令⾏安装的⽅式如下
- $ `sudo aptitude install nvidia-driver-435 --without-recommends`
- 不同的编号⽀持不同的显卡，如果是1080ti等⽐较新的显卡，直接⽤编号最⾼的应该就没问题。⽐较⽼旧的显卡，可以到nvidia的官⽅⽹站查询。
- 使⽤`--without-recommends`可以只安装需要的东西，其他推荐安装的东西可以都不安装了，省了很多空间
- 安装完成之后，需要重启⼀下系统 $ `sudo reboot`
- 很多教程说要去下载sh的驱动⽂件，进⾏编译安装，这⾥不太推荐，因为很⿇烦⽽且容易出问题，ubuntu对⾮开源驱动的⽀持还是⽐较好的，直接⽤cuda库⾥⾯的驱动就可以。
- 关于驱动的安装，有⽂章提到过cuda⾥⾯⾃⼰带的驱动是有问题的，所以需要单独装驱动，⽽不是使⽤cuda⾥⾯⾃⼰带的。但是我们这是测试过的发现，就算装的不是最新的驱动，cuda也会尝试给更新到最新，⽽且看上去没啥问题，也许是特定版本的驱动才会出现的问题。这个需要具体问题具体分析了
- 推荐看下这篇博客：https://blog.csdn.net/weixin_43820996/article/details/100676292
- 之后使用如下命令检测是否安装成功
    * $ `nvidia-smi`
    * $ `nvidia-smi -lms 3000` 这里表示3s执行一次`nvidia-smi`命令


4 ） **conda安装**

4.1 **conda概述**
- conda是一个开源包管理系统和环境管理系统，用于安装多个版本的软件包机器依赖关系，并在他们之间轻松切换
- 它适用于Linux, OSX, Windows, 是位Python程序创建的，但可以打包和分发任何软件
- Anaconda 是一个开源的Python发行版本，包含了conda、python等很多科学包及依赖项
- 因为包含了大量的科学包，所以Anaconda的安装包比较大，如果为了省时间，也可以选择Miniconda这个较小发行版
- Miniconda是最小的conda安装环境，只带了基本的conda和Python, 可以根据自己的需要选择下载
- Miniconda下载地址：https://docs.conda.io/en/latest/miniconda.html#linux-installers
- Anaconda下载地址：https://www.anaconda.com/distribution/#download-section
- 清华大学计算机协会 Tuna 也提供了下载: https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/

4.2 **安装**

- 这里我们选择Miniconda来进行安装
- 如果不是在server上下载，那么需要把下载好的文件使用 rsync, ssh 等命令上传到linux服务器上
- 我们下载的是个大的脚本，没有可执行权限，需要对该文件进行设置下如： $ `chmod a+x Miniconda3-latest-Linux-x86_64.sh`
- 然后再执行：$ `./Miniconda3-latest-Linux-x86_64.sh`
- 上述安装脚本基本是全自动的，包括安装路径，建议按照默认
- 最后安装脚本会提示，是否在bashrc里面加一个环境初始化设置，这里推荐是让脚本加上，如果不让它设置，自己也得手动设置
- 注意，这里环境是全新安装的，只用Miniconda作为开发环境的管理，不需额外设置，但是如果机器上已经有安装好的Python环境，需谨慎操作，可能会产生很多问题
- 安装按成后，重启shell，让conda的环境设置生效

4.3 **conda的配置**

- conda安装源默认在海外，非常慢，国内很多镜像站也提供一些源，可进行配置，具体参考[这里](https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/)
- 在Home目录下，进行编辑 $ `cd ~ & nano .condarc`
    ```conf
    channels:
    - defaults
    show_channel_urls: true
    channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda
    default_channels:
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro
    - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
    custom_channels:
    conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    ```

3 ） **cuda, cudnn的安装**

注：这里手动安装，过程可能比较麻烦，建议看后面框架部分，通过conda安装cuda，此部分可以直接跳过!

3.1 **下载cuda**

- cuda是Nvidia的GPU加速计算库
- conda都可以安装cuda
- 去[这⾥下载](https://developer.nvidia.com/cuda-10.0-download-archive)ubuntu18.04对应的最新的cuda10
- 作者下载的是deb（local）的版本，这是⼀个deb⽂件，装好之后，就可以将整个cuda10的仓库放在本地，省去在线下载的⿇烦
- ⽂件名为：`cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb`

3.2 **下载cudnn**

- 注册⼀个nvidia的开发者帐号，下载cudnn7.4, 这⾥下载的是cuda10对应的deb版本，不要下载错了
- 文件名为：libcudnn7_7.4.1.5-1+cuda10.0_amd64.deb

3.3 **安装cuda库**

- 直接⽤dpkg安装这个⽂件就好了。装好了整个cuda的仓库就在本地了。

```shell
sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb
sudo apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub # 执⾏这⼀⾏是为了导⼊key
sudo aptitude update # 执⾏升级，让cuda库起作⽤
```
- 这⾥安装的其实是⼀个cuda的apt仓库，相当于把cuda的apt仓库的本地版本。到这⾥，cuda还没有安装好

3.5 **继续安装cuda**

- 直接执⾏下⾯的命令安装就可以了
- $ `sudo aptitude install cuda-runtime-10-0 --without-recommends`
- 因为我这⾥只是要运⾏这些框架，并不是要编译什么东西，所以这⾥装的是cuda的runtime，也就是不带任何⼯具，并且也没装任何额外的开发包，所以很快⽽且占⽤空间也不多
- 如果需要从源代码编译⼀些使⽤cuda的框架，那么还是需要⽼⽼实实装cuda ：$ `sudo aptitude install cuda`
- 在18.04版本之前，cuda都是单独安装的，安装到了`/usr/local`下⾯，所以需要⼀些其他的设置，⽽现在，cuda直接安装到`/usr/lib`下⾯去了，就不需要那些单独的设置了

3.6 **安装cudnn**

- 因为我们下载的是deb，所以直接安装就好了，很简单：$`sudo dpkg -i libcudnn7_7.4.1.5-1+cuda10.0_amd64.deb`

3.7 **参考链接**

- https://blog.csdn.net/pursuit_zhangyu/article/details/87621187
- https://blog.csdn.net/kaixinjiuxing666/article/details/80321124
- https://blog.csdn.net/xuguosheng1992/article/details/93207937

4 ) **安装tensorflow**

- 如果tensorflow的安装时，版本碰到了⼀些⼩问题，存在一些错位或不兼容，想要在我们现在已经装好的环境⾥⾯使⽤tensorflow，就有下⾯三种⽅式了：
    * 从源代码编译tensorflow，开启cuda10的⽀持，顺便可以做⼀下优化编译
        * 这个⽅案⽐较不好的是tf的代码在google的服务器上，国内需要梯⼦才能下载，⽽且编译要⼏个⼩时，很⿇烦，不太推荐
    * 使⽤nvidia-docker，这是个很不错的主意，⽽且还能提供环境隔离等，并且不限host机的cuda环境，因为只跟docker内部的cuda的环境有关
        * 这个⽅案安装nvidia-docker已经简单很多了，⼏乎是傻⽠式操作，但是docker的使⽤还是有些复杂，⽽且真⼼不如在本地直接安装⽅便好⽤，值得考虑，但是这⾥不推荐
    * 使⽤⾃带cuda10⽀持的⾮官⽅编译tensorflow，有很多热⼼⽹友提供了⾃⼰编译好的⽀持cuda10的tensorflow
        * 存在安全和兼容问题，如：compute capability不兼容等，慎重考虑
        * 注意：compute capability 是api版本和算力无关
- tf官⽅放在pypi⾥⾯的tensorflow-gpu从1.7版本开始就默认开启了avx2的指令集优化
- 如果电脑的cpu型号⽐较⽼，例如e3 v2系列的cpu，安装完成之后，运⾏的时候会出现段错误之类的问题，这种情况只能考虑⾃⼰编译tf或者换cpu了
- conda中的tf版本，默认开启了mkl的优化，这是pypi里面版本没有的，大概提升30%左右
- 安装，激活conda环境，使用命令：$ `pip install --upgrade tensorflow-gpu==1.14 -i https://pypi.tuna.tsinghua.edu.cn/simple`
- 具体参考之前的博客：https://blog.csdn.net/Tyro_java/article/details/104422693
- 或直接使用conda安装 $ `conda install tensorflow-gpu==1.15`
- 如果没有GPU, 可以安装CPU版本：$ `conda install tensorflow==1.15`
- 这里1.15是tf1.x最后一个版本
- 其实tf2.x挺好用，因为历史遗留项目，很多都是基于1.x的
- 在安装的时候会列出tf依赖的cuda和cudnn的版本，可以记录下，为后续其他框架安装做准备
- 例如：
    ```shell
    cudatoolkit pkgs/main/linux-64::cudatoolkit-10.0.130-0
    cudnn pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0
    ```

5 ) **安装pyTorch**

- 官网上给出了安装方式，涉及多个不同环境，为了统一多个框架共存，安装相同版本的cuda，这里指定cuda版本10.0
    * $ `conda install pytorch torchvision torchtext cudatoolkit=10.0 -c pytorch`
    * $ `conda install pytorch torchvision torchtext cpuonly -c pytorch`
- 这里的torchtext是否使用可以进行自己的需求来进行选择
- 或者重开⼀个终端，使用pip来进行安装，输⼊
    ```shell
    pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36mlinux_x86_64.whl
    pip3 install torchvision
    ```
- 这个安装命令是pyTorch官⽅给的，官⽅很贴⼼的给出了基本所有可能⽤到的环境（conda，pip，windows，linux）下的安装命令。⽐tf社区强多了
- 测试pyTorch的安装
    ```shell
    import torch
    x = torch.rand(5, 3)
    print(x)
    torch.cuda.is_available()
    ```

5 ） **安装mxnet**

- 早期mxnet为了用户使用方便，提供各个不同的cuda，mkl等的编译版本供使用，但是一直没有提供conda的安装方式
- 不过conda里面也带来了pip，所有使用pip进行安装
    ```shell
    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 设置pypi国内镜像源，做一次就可以
    pip install mxnet-cu100mkl gluoncv gluonts
    ```
- 注意这里安装的是u100mkl版本，代表这里安装的是mxnet，是在cuda10.0下编译，开启了mkl支持
- cpu版本可以这样安装
    ```shell
    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 设置pypi国内镜像源，做一次就可以
    pip install mxnet-mkl gluonc gluonts
    ```
- 这里使用Tuna的pypi镜像来进行安装，速度更快了
- mkl是intel的数学加速计算库，用于intel cpu上的加速运算，如果没有GPU, 一定要安装整个库,可以获得30%左右性能提升
- 一些旧的版本上会要求首先装一个依赖库libgfortran3, $ `sudo aptitude install libgfortran3` 如果没有特别提示, 就不用管它

### 对各个框架跑数据集进行测试

- http://yann.lecun.com/exdb/mnist/ 下载数据集
- 下载如下数据集，共4个
    * train-images-idx3-ubyte.gz:  training set images (9912422 bytes)
    * train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)
    * t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)
    * t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)
- 分别编写各个测试脚本: `mnist_tf.py`, `mnist_torch.py`, `mnist_mx.py` 可以从各个官方文档上找到相关测试代码，也可以自己写
- 监控脚本运行时候是否利用GPU $ `nvidia-smi -lms 1000`

### 总结

- mxnet的社区和学习资料都是中⽂为主的，对国⼈很友好
- ⽬前发展势头最猛的pyTorch也是很值得期待的，特别是1.0发布之后，有facebook的支持，整个⽣态也都在完善起来
- tf虽然有各种问题，但是⽬前⽤⼾群最⼴，⽂档资料最⻬全，model-zoo最⼤的，⽽且有slim这样的⼯业级框架加持，tf绝对是⼤多数场景的不⼆之选